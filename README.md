# ğŸ§  RAG-ARC: Retrieval-Augmented Generation Architecture

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)](https://fastapi.tiangolo.com/)
[![FAISS](https://img.shields.io/badge/FAISS-GPU/CPU-FF6F00.svg)](https://github.com/facebookresearch/faiss)
[![Pydantic v2](https://img.shields.io/badge/Pydantic-v2-ffa000.svg)](https://docs.pydantic.dev/)

*A modular, high-performance Retrieval-Augmented Generation framework with multi-path retrieval, graph extraction, and fusion ranking*

[ğŸ“˜ ä¸­æ–‡æ–‡æ¡£](README-CN.md) â€¢ [â­ Key Features](#key-features) â€¢ [ğŸ—ï¸ Architecture](#architecture) â€¢ [ğŸš€ Quick Start](#quick-start)

## ğŸ¯ Project Overview

**RAG-ARC** is a modular Retrieval-Augmented Generation (RAG) framework designed to build efficient, scalable architectures that support multi-path retrieval, graph structure extraction, and fusion ranking. The system addresses key challenges in traditional RAG systems when processing unstructured documents (PDF, PPT, Excel, etc.) such as information loss, low retrieval accuracy, and difficulty in recognizing multimodal content.

### ğŸ¯ Core Use Cases

ğŸ§© **Full RAG Pipeline Support**: Covers the complete pipelineâ€”from document parsing, text chunking, and embedding generation to multi-path retrieval, graph extraction, reranking, and knowledge graph management.<br>
ğŸ“š **Knowledge-Intensive Tasks**: Ideal for question answering, reasoning, and content generation tasks that rely on large-scale structured and unstructured knowledge, ensuring high recall and semantic consistency.<br>
ğŸŒ **Cross-Domain Applications**: Supports both Standard RAG and GraphRAG modes, making it adaptable for academic research, personal knowledge bases, and enterprise-level knowledge management systems.<br>

## ğŸ—ï¸ Architecture

<div align="center">
<img src="assets/architecture.png" alt="RAG-ARC Architecture" width="95%"/><br>
RAG-ARC System Architecture Overview
</div>

## ğŸ”§ Key Features

RAG-ARC introduces several key innovations that together build a sophisticated integrated framework:

### ğŸ“ Multi-Format Document Parsing
- Support for docx, pdf, ppt, excel, html and other file types
- Flexible parsing strategies with OCR and layout-aware PDF parsing (via dots_ocr module)
- Native and VLM-based OCR capabilities

### âœ‚ï¸ Text Chunking & Vectorization
- Multiple chunking strategies (token-based, semantic, recursive, markdown headers)
- Integration with HuggingFace embedding models for vector representation
- Configurable chunk size and overlap parameters

### ğŸ” Multi-Path Retrieval
- Combined BM25 (sparse retrieval), Dense retrieval (Faiss-GPU), and Tantivy full-text search
- Reciprocal Rank Fusion (RRF) for result merging
- Configurable weights and fusion methods

### ğŸŒ Graph Structure Extraction
- Extracts entities and relations from facts to build structured knowledge graphs
- Seamlessly integrates with Neo4j graph database
- Enables knowledge-graph-driven reasoning and QA

### ğŸ§  GraphRAG
- Lightweight, incrementally updatable graph construction suitable for enterprise deployment
- Incorporates Subgraph PPR (Personalized PageRank): Compared to HippoRAG2's full-graph PPR, subgraph PPR achieves higher reasoning precision and efficiency

### ğŸ“ˆ Re-ranking (Rerank)
- Qwen3 model for precise result re-ranking
- LLM-based and listwise re-ranking strategies
- Score normalization and metadata enrichment

### ğŸ§© Modular Design
- Factory pattern for LLM, Embedding, Retriever component creation
- Layered architecture: config, core, encapsulation, application, api
- Singleton pattern for tokenizer management and database connections
- Shared mechanism for retriever and embedding model instance reuse to improve system performance

## ğŸ“Š Performance

Built upon the HippoRAG2 evolution, RAG-ARC delivers significant improvements in both efficiency and recall performance:

- ğŸš€ **22.9% Token Cost Reduction**
Through optimized prompt strategies, it reduces token consumption without sacrificing accuracy.
- ğŸ¯ **5.3% Recall Rate Increase**
Pruning-based optimizations yield more comprehensive and relevant retrieval.
- ğŸ” **Incremental Knowledge Graph Updates**
Supports updating graph data without full reconstructionâ€”reducing computational and maintenance overhead.

<div align="center">
  <h3>ğŸ“Š Performance Comparison</h3>
  <img src="assets/accuracy_comparison.png" alt="Accuracy Comparison" width="80%" style="margin-bottom: 20px;"/><br>
  <img src="assets/recall_comparison.png" alt="Recall Comparison" width="80%" style="margin-bottom: 20px;"/><br>
  <img src="assets/token_cost_comparison.png" alt="Token Cost Comparison" width="80%"/>
</div>


## ğŸ“ Project Structure

```
RAG-ARC/
â”œâ”€â”€ ğŸ“ api/                       # API layer (FastAPI routes/MCP integration)
â”‚   â”œâ”€â”€ routers/                  # API route definitions
â”‚   â”œâ”€â”€ config_examples/          # Configuration examples
â”‚   â””â”€â”€ mcp/                      # MCP server implementation
â”‚
â”œâ”€â”€ ğŸ“ application/               # Business logic layer
â”‚   â”œâ”€â”€ rag_inference/            # RAG inference module
â”‚   â”œâ”€â”€ knowledge/                # Knowledge management
â”‚   â””â”€â”€ account/                  # User account management
â”‚
â”œâ”€â”€ ğŸ“ core/                      # Core capabilities
â”‚   â”œâ”€â”€ file_management/          # File parsing and chunking
â”‚   â”œâ”€â”€ retrieval/                # Retrieval strategies
â”‚   â”œâ”€â”€ rerank/                   # Re-ranking algorithms
â”‚   â”œâ”€â”€ query_rewrite/            # Query rewriting
â”‚   â””â”€â”€ prompts/                  # Prompt templates
â”‚
â”œâ”€â”€ ğŸ“ config/                    # Configuration system
â”‚   â”œâ”€â”€ application/              # Application configs
â”‚   â”œâ”€â”€ core/                     # Core module configs
â”‚   â””â”€â”€ encapsulation/            # Encapsulation configs
â”‚
â”œâ”€â”€ ğŸ“ encapsulation/             # Encapsulation layer
â”‚   â”œâ”€â”€ database/                 # Database interfaces
â”‚   â”œâ”€â”€ llm/                      # LLM interfaces
â”‚   â””â”€â”€ data_model/               # Data models and schemas
â”‚
â”œâ”€â”€ ğŸ“ framework/                 # Framework core
â”‚   â”œâ”€â”€ module.py                 # Base module class
â”‚   â”œâ”€â”€ register.py               # Component registry
â”‚   â””â”€â”€ config.py                 # Configuration system
â”‚
â”œâ”€â”€ ğŸ“ test/                      # Test suite
â”‚
â”œâ”€â”€ main.py                      # ğŸ¯ Main application entry point
â”œâ”€â”€ app_registration.py          # Component initialization
â”œâ”€â”€ pyproject.toml               # Project dependencies
â””â”€â”€ README.md                    # Project documentation
```

## ğŸš€ Quick Start

### ğŸ³ Docker Deployment (Recommended)

**Three-step deployment:**

```bash
# 1. Clone the repository
git clone https://github.com/DataArcTech/RAG-ARC.git
cd RAG-ARC

# 2. Build Docker images (one-time setup)
./build.sh

# 3. Start all services
./start.sh
```

The deployment includes:
- âœ… **PostgreSQL 16**: Metadata storage
- âœ… **Redis 7**: Caching layer
- âœ… **Neo4j**: Knowledge graph database
- âœ… **RAG-ARC App**: FastAPI application with GPU support

**What the scripts do:**

`build.sh`:
- Checks Docker environment
- Creates .env configuration
- Selects CPU/GPU mode (auto-detect NVIDIA GPU)
- Pulls base images (PostgreSQL, Redis, Neo4j)
- Builds RAG-ARC application image

`start.sh`:
- Creates Docker network
- Starts all 4 containers
- Waits for services to be ready
- Verifies deployment

`stop.sh`:
- Stops all running containers (keeps data)

`cleanup.sh`:
- Removes all containers and Docker volumes
- Removes Docker network
- **Keeps local data directories** (`./data`, `./local`, `./models`)
- Use when you want to clean Docker resources but keep your data

`clean-docker-data.sh`:
- Removes all containers and Docker volumes
- **Also removes local data directories** (`./data/postgresql`, `./data/neo4j`, `./data/redis`, `./data/graph_index_neo4j`)
- Use when you want a complete cleanup (âš ï¸ **This will delete all data!**)

**Access the service:**
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs

ğŸ“– **See [Docker Deployment Guide (English)](README.Docker.md) or [Dockeréƒ¨ç½²æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰](README.Docker-CN.md) for detailed instructions and troubleshooting**

### ğŸ’» Local Installation

```bash
# 1. Clone the repository
git clone https://github.com/DataArcTech/RAG-ARC.git
cd RAG-ARC

# 2. Install uv if not already installed
# Recommended: Using China mirror (faster in China)
curl -LsSf https://astral.ac.cn/uv/install.sh | sh
# Alternative: Using official installer
# curl -LsSf https://astral.sh/uv/install.sh | sh
# Or add to PATH: export PATH="$HOME/.local/bin:$PATH"

# 3. Install dependencies (uv will automatically create a virtual environment)
# Tsinghua mirror is configured in pyproject.toml
uv sync

# 4. Copy and configure environment variables
cp .env.example .env
# Edit .env to configure your settings
```

### âš™ï¸ Configuration

RAG-ARC uses a modular configuration system. Key configuration files are located in `config/json_configs/`, where you can control which GPU each model uses, which models are used in business processes, and other different parameters:

- `rag_inference.json`: RAG retrieval configuration
- `knowledge.json`: Knowledge management configuration
- `account.json`: User account configuration

### ğŸƒ Running the Service

```bash
# Start the FastAPI server (uv run automatically manages the virtual environment)
uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### ğŸ§ª Example Usage

```bash
# Upload a document
curl -X POST "http://localhost:8000/knowledge" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -F "file=@/path/to/your/document.pdf"

# Chat with the RAG system
curl -X POST "http://localhost:8000/rag_inference/chat" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is RAG-ARC?"}'

# Get Token (Login)
curl -X POST "http://localhost:8000/auth/token" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=YOUR_USERNAME&password=YOUR_PASSWORD"

# Register a new user
curl -X POST "http://localhost:8000/auth/register" \
  -H "Content-Type: application/json" \
  -d '{"name": "New User", "user_name": "YOUR_USERNAME", "password": "YOUR_PASSWORD"}'

# Create a new chat session
curl -X POST "http://localhost:8000/session" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"

# List messages in a session
curl -X GET "http://localhost:8000/session/YOUR_SESSION_ID/messages" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

### WebSocket streaming chat (Python example, requires websockets library):

```python
import asyncio
import websockets

async def chat():
    uri = 'ws://localhost:8000/rag_inference/stream_chat/YOUR_SESSION_ID'
    async with websockets.connect(uri, additional_headers=[('Cookie', 'auth_token=YOUR_ACCESS_TOKEN')]) as ws:
        await ws.send('Hello, RAG-ARC!')
        print(await ws.recv())

asyncio.run(chat())
```

## ğŸ› ï¸ Technology Stack

- **Backend**: Python 3.11+
- **Framework**: FastAPI
- **Vector Database**: FAISS (GPU/CPU)
- **Graph Database**: Neo4j
- **Full-text Search**: Tantivy
- **ML Frameworks**: HuggingFace Transformers, PyTorch
- **Data Validation**: Pydantic v2
- **Serialization**: Dill
- **LLM Support**: Qwen3, OpenAI API, HuggingFace models

## ğŸ”§ Advanced Configuration

### Multi-Path Retrieval Configuration

RAG-ARC supports configurable multi-path retrieval with the following components:

1. **Dense Retrieval**: Uses FAISS for vector similarity search
2. **Sparse Retrieval**: BM25 implementation via Tantivy
3. **Graph Retrieval**: Neo4j-based knowledge graph retrieval with Pruned HippoRAG

The fusion method can be configured to use:
- **Reciprocal Rank Fusion (RRF)**: Default method for combining results
- **Weighted Sum**: Custom weights for each retrieval path
- **Rank Fusion**: Rank-based combination approach

### GraphRAG Implementation

RAG-ARC implements an enhanced GraphRAG approach based on HippoRAG2 with key improvements:

1. **Subgraph PPR**: Instead of computing Personalized PageRank on the entire graph, RAG-ARC computes it on relevant subgraphs for better efficiency and accuracy
2. **Query-Aware Pruning**: Dynamically adjusts the number of neighbors retained during graph expansion based on entity relevance to the query
3. **Incremental Updates**: Supports updating the knowledge graph without full reconstruction

### Document Processing Pipeline

The document processing pipeline consists of several stages:

1. **File Storage**: Documents are stored in a configurable storage backend (local filesystem or cloud storage)
2. **Parsing**: Multiple parsers support different document types:
   - Native parsers for standard formats (PDF, DOCX, PPTX, etc.)
   - OCR parsers for scanned documents (using DOTS-OCR or VLM-based approaches)
3. **Chunking**: Text is split into chunks using configurable strategies:
   - Token-based chunking
   - Semantic chunking
   - Recursive chunking
   - Markdown header-based chunking
4. **Indexing**: Chunks are indexed in multiple systems:
   - FAISS for dense retrieval
   - Tantivy for sparse retrieval
   - Neo4j for graph-based retrieval

## ğŸ“Š API Endpoints

RAG-ARC provides a comprehensive REST API with the following key endpoints:

### Knowledge Management
- `POST /knowledge`: Upload documents
- `GET /knowledge/list_files`: List user documents
- `GET /knowledge/{doc_id}/download`: Download documents
- `DELETE /knowledge/{doc_id}`: Delete documents

### RAG Inference
- `POST /rag_inference/chat`: Chat with the RAG system
- `WebSocket /rag_inference/stream_chat/{session_id}`: WebSocket-based streaming chat

### User Management
- `POST /auth/register`: User registration
- `POST /auth/token`: User authentication (login)

### Session Management
- `POST /session`: Create chat sessions
- `GET /session`: List user sessions
- `GET /session/{session_id}`: Get session details
- `DELETE /session/{session_id}`: Delete sessions

## ğŸ”’ Security & Authentication

RAG-ARC implements JWT-based authentication with the following features:

- User registration and login
- Role-based access control
- Document-level permissions (VIEW/EDIT)
- Secure password hashing with bcrypt
- Token refresh mechanism

## ğŸ“ˆ Monitoring & Observability

RAG-ARC includes built-in monitoring capabilities:

- Logging with configurable levels
- Performance metrics collection
- Health check endpoints
- Indexing status monitoring

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how you can help:

### ğŸ’» Code Contributions

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Open a Pull Request

### ğŸ”§ Development Guidelines

- **New Parsing Strategies**: Implement custom document parsing logic
- **Retrieval Algorithms**: Add new retrieval methods and fusion techniques
- **Reranking Models**: Integrate additional reranking models
- **Chunking Methods**: Implement novel text chunking approaches

## ğŸ“ Contact

For questions, issues, or feedback, please open an issue on GitHub or contact the maintainers.

---

## ğŸ“š License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.